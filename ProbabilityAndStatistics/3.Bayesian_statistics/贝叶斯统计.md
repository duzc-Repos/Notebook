# Summary

## 1.1 三种信息

* 总体信息 $m(x)$
* 样本信息 $p(\mathcal{X} \mid \theta)$
* 先验信息 $\pi(\theta)$

## 1.2 后验信息

$$
\pi(\theta \mid \mathcal{X}) = \frac {\pi(\theta) p(\mathcal{X} \mid \theta)}{m( x)}
$$

* 后验信息是 三种信息的综合

## 1.3 充分统计量

* 定义：$T(\mathcal{X})$ 是充分统计量 $\iff p(\mathcal{X} \mid T(\mathcal{X}), \theta) \varpropto p(\mathcal{X} \mid T(\mathcal{X}))$ 

* __因子分解定理（充要条件）__：
  * $p(\mathcal{X} \mid \theta) = g(T(\mathcal{X}), \theta)h(\mathcal{X})$
  * $\pi(\theta \mid T(\mathcal{X})) = \pi(\theta \mid \mathcal{X})$

## 1.4 三个基本问题

* 如何确定先验?
  * 共轭先验
  * 利用经验 或者 历史数据
  * 
* __如何计算后验?__
  * 根据贝叶斯公式计算
  * 利用共轭先验
  * 利用充分统计量
  * MCMC方法
* 如何进行推断?



# Question1: How to inference?

* 后验分布$\pi(\theta \mid \mathcal{X})$集合三种信息，所有有关$\theta$的点估计、区间估计、假设检验等统计推断均是按一定方式从后验分布提取信息
* __条件观点__：推断只考虑出现的样本，与未出现的样本无关



## 2.1 点估计

* __贝叶斯估计 $\hat{\theta}_{B}$__
  * 最大后验估计 $\hat{\theta}_{MD} = \arg\max_\limits{\theta \in \Theta} \pi(\theta \mid \mathcal{X})$
  * 后验中位数估计 $\hat{\theta}_{Me} = \arg \left( \int_{-\infty}^{\hat{\theta}_{Me}} \pi(\theta \mid \mathcal{X}) {\rm d}\theta = 0.5 \right)$
  * __后验期望估计 $\hat{\theta}_{E} = \rm{E}(\theta \mid \mathcal{X})$__

* __估计的误差__：后验均方差
  $$
  \begin{align} 
  MSE(\theta \mid \mathcal{X}) &= \rm{E}_{\theta \mid \mathcal{X} \sim \pi(\theta \mid \mathcal{X} )}(\hat\theta_{B} - \theta)^2 \\
  &= Var(\theta \mid \mathcal{X}) + (\hat\theta_{B} - \hat\theta_E)^2
  \end{align}
  $$



## 2.2 区间估计

* $1-\alpha$可信区间：$\exists \hat\theta_{L}(\mathcal{X}), \hat\theta_{H}(\mathcal{X}), \int_{\hat\theta_{L}}^{\hat\theta_{H}} \pi(\theta \mid \mathcal{X}){\rm d}\theta \geq 1 - \alpha$

  * 单侧致信区间

* __最大后验密度(HPD)__可信区间：

  * $P(C \mid \mathcal{X}) = 1 - \alpha$

  * $\forall \theta_1 \in C, \theta_2 \not\in C, \pi(\theta_1 \mid \mathcal{X}) \geq \pi(\theta_2 \mid \mathcal{X})$

  * __Algorithm__:

    > 1. 给定$k$, 求解$\pi(\theta \mid \mathcal{X}) = k$, 得$C = [\theta_1(k), \theta_2(k)]$
    >
    > 2. 计算$P(C \mid \mathcal{X}) = \int_{C} \pi(\theta \mid \mathcal{X}) {\rm d}\theta$
    >
    >    if $P(C \mid \mathcal{X}) > 1-\alpha$
    >
    >    ​		$k += \delta$
    >
    >    elif $P(C \mid \mathcal{X}) > 1-\alpha$
    >
    >    ​		$k -= \delta$
    >
    > 3. 重复1，2，直到elif $P(C \mid \mathcal{X}) - (1-\alpha) \leq \epsilon$

    

## 2.3 假设检验

* 原假设 $H_0: \theta \in \Theta_0$，备择假设$H_1: \theta \in \Theta_1$
* __先验概率比__：$\frac{\pi_0}{\pi_1} = \frac{\pi(\theta \in \Theta_0 )}{\pi(\theta \in \Theta_1)}$
* __后验概率比__: $\frac{\alpha_0}{\alpha_1} = \frac{\pi(\theta \in \Theta_0 \mid \mathcal{X})}{\pi(\theta \in \Theta_1 \mid \mathcal{X})} = \int_{\Theta_0} \pi(\theta)p(x\mid \theta) {\rm d}\theta / \int_{\Theta_1} \pi(\theta)p(x\mid \theta) {\rm d}\theta$

* __贝叶斯因子__：$B^{\pi}(\mathcal{X}) = \frac{\alpha_0 / \alpha_1}{\pi_0 / \pi_1} = \frac{\alpha_0 \pi_1}{\alpha_1\pi_0}$
  * 表示数据$\mathcal X$支持$\Theta_0$的支持程度
  * 两种机会比相除会极大的消除先验带来的影响
* 多种假设情况
  * 简单 对 简单：$B^{\pi}(\mathcal{X}) = \frac{p(\mathcal{X} \mid \theta_0)}{p(\mathcal{X} \mid \theta_1)}$
    * 仅依赖样本
  * 复杂 对 复杂：$B^{\pi}(\mathcal{X}) = \frac{m_0(x)}{m_1(x)}$
    * 仍然依赖于先验分布
  * 简单 对 复杂：$B^{\pi}(\mathcal{X}) = \frac{p(\mathcal{X} \mid \theta_0)}{m_1(x)}$



## 2.4 预测

* $X \sim p(x \mid \theta),\ \theta$未知，未对$X$进行观测，如何对$X$预测? 
  * $m(x) = \int_\Theta \pi(\theta)p(x \mid \theta){\rm d}\theta$----------------------------------------------利用先验
* $x_1, \cdots, x_n \sim p(\mathcal{X} \mid \theta), \ \theta$未知，如何对$X$预测?
  * $m(x_{n+1} \mid \mathcal{X}) = \int_{\Theta} p(x_{n+1} \mid \theta) \pi(\theta \mid \mathcal{X}) {\rm d}\theta$
* $x_1, \cdots, x_n \sim p(\mathcal{X} \mid \theta), \ \theta$未知，如何对$Z \sim g(z \mid \theta)$预测?
  * $m(z \mid \mathcal{X}) = \int_{\Theta} g(x_{n+1} \mid \theta) \pi(\theta \mid \mathcal{X}) {\rm d}\theta$



## 2.5 似然原理

* $L(\theta) = p(\mathcal{X} \mid \theta) = \prod\limits_{i=1}^n p(x_i \mid \theta)$包含所有与试验有关的$\theta$的信息
* 若两个似然函数成比例，则含有相同的关于$\theta$的信息



# Question2: How to define a prior distribution?

