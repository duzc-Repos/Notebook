# 第四章 无数据决策问题（仅用先验信息）

## 4.1 决策问题三要素

* 状态集 $\Theta = \{\theta_1, \cdots, \theta_n\}$: 参数空间，参数可能的取值，
* 行动集 $\mathcal{A} = \{a_1, \cdots, a_m\}$: 至少有两个，供决策选择使用
* 收益$(Q)$、损失$(L)$、效用$(U)$：
  * 收益函数 $Q(\theta_i, a_j) = Q_{ij}$: 当处于状态$\theta_i$是采取行动$a_j$带来的收益
  * 效用函数: 钱在心目中的价值，对收益再加一个函数，即$U(\theta_i, a_j) = U(Q(\theta_i, a_j))$
  * __损失函数__: 该赚的钱没有赚到
    * $L(\theta_i, a_j) = \max\limits_{a \in \cal{A}}Q(\theta_i, a) - Q(\theta_i, a_j)$
    * $L(\theta_i, a_j) = \max\limits_{a \in \cal{A}}U(\theta_i, a) - U(\theta_i, a_j)$
* 一个决策问题是给定的 $\iff$ 三要素均是明确的

## 4.2 决策准则

### 4.2.1 行动的容许性

* __定义__: 给定决策问题，若对$\forall\theta_i \in \Theta, Q(\theta_i, a_0) \geq Q(\theta_i, a')$, 并且$\exist \theta_0 \in \Theta, Q(\theta_0, a_0) > Q(\theta_0, a')$, 则行动$a'$是__非容许的__，反之则为容许的。
  * 从$a_0, a'$行动对应的$\theta \sim Q$的图像上看，$a_0$均再$a'$上方。

### 4.2.2 决策准则

决策准则关心的是当给定三要素后如何做决策的问题，即如何选择最优的决策

* 悲观准则：最差中求最好，$ a_{opt} = \arg\max\limits_{a_j \in \cal{A} } \min\limits_{\theta_i \in \Theta} Q(\theta_i, a_j)$

* 乐观准则：最大中取最大，$ a_{opt} = \arg\max\limits_{a_j \in \cal{A} } \max\limits_{\theta_i \in \Theta} Q(\theta_i, a_j)$

* 折中准则 / Hurwicz准则:

  * 乐观系数$\alpha \in [0, 1]$
  * $a_{opt} = \arg\max\limits_{a_j \in \cal{A} } \left( \alpha\max\limits_{\theta_i \in \Theta} Q(\theta_i, a_j) + (1-\alpha)\min\limits_{\theta_i \in \Theta} Q(\theta_i, a_j)  \right)$

  * $\alpha=0$为悲观准则，$\alpha=1$为乐观准则

* __先验期望准则__：
  * 给定参数的先验$\theta \sim \pi(\theta)$，记$E_{\theta \sim \pi(\theta)}Q(\theta, a_j)$为行动$a_j$的__先验期望收益__
  * $a_{opt} = \arg\max\limits_{a_j \in \cal{A}} E_{\theta \sim \pi(\theta)}Q(\theta, a_j) = \arg\max\limits_{a_j \in \cal{A}} \int_\Theta Q(\theta, a_j)\pi(\theta)\ {\rm d}\theta $
  * 悲观、乐观、这种这些准则均是选用特定先验分布的产物



# 第五章 贝叶斯决策（后验信息，抽样+先验）

## 5.1 贝叶斯决策问题

* 可观察的随机变量$X \sim p(x|\theta_i)$
* 参数空间$\theta_i \in \Theta$
* 行动集$a_j \in \cal{A}$
* __损失函数__$L(\theta_i, \delta_j(x))$
* __决策函数__$\delta_j(x) \in \cal D$

## 5.2 后验风险准则

### 5.2.1 后验风险

* 给定参数的先验$\theta \sim \pi(\theta)$以及样本的似然函数$x \sim p(x \mid \theta)$可得后验为$\pi(\theta \mid x) = p(x\mid \theta)\pi(\theta)/m(x)$
* 行动$a_j$的__后验风险__为$R(a_j \mid x) = E_{\theta \mid x \sim \pi(\theta \mid x)} L(\theta, a_j)$

> 假设，$x$的可能取值有$k$个，则此种定义下的后验风险，是$a_j与x$的二元函数，最优行动$a_{opt}$是随着样本$x$的取值发生变化的，所以需要建立__决策函数__的概念。

### 5.2.2 决策函数的后验风险

* __决策函数__：$\delta: \cal{X} \rightarrow \cal{A}$称为一个决策函数。所有$\cal{X} \rightarrow \cal{A}$的决策函数组成的集合称为__决策函数类__，记为$\cal{D} = \{\delta_j(x)\}$
  * e.g $\cal{X} = \{0, 1, 2\}, \cal{A}=\{a_1, a_2\}$，则决策函数共有$2^3 = 8$个

* __决策函数的后验风险__：$R(\delta \mid x) = E_{\theta \mid x \sim \pi(\theta \mid x)} \left[ L(\theta, \delta(x)) \right],\ x \in \cal X,\ \theta \in \Theta$
* __后验风险准则 以及 最优决策函数/贝叶斯决策函数/贝叶斯解/贝叶斯估计__: 

$$
\delta_{opt} = \arg\min_\limits{\delta_j \in D} R(\delta_j \mid x)
$$

> Question: 对所作决策问题进行抽样是否值得?
>
> 需要比较 __获取抽样信息的花费__ 与 __获取抽样信息带来的收益__ 进行比较

## 5.4 抽样信息期望值

* __完全信息__：决策者获得的信息足以确定某一个状态即将发生
  
* 完全信息是使决策者收益最大的信息（损失最小）
  
* __完全信息期望值__:  $EVPI = E_{\theta \sim \pi(\theta)} \left[ \max_\limits{a_j \in \cal{A}}Q(\theta_i, a_j) \right] - \max_\limits{a_j \in \cal{A}}E_{\theta \sim \pi(\theta)} \left[ Q(\theta_i, a_j) \right]$
  * 第一项是获得完全信息时的收益
  * 第二项时按先验期望准则时的收益
  * 两者相减即为EVPI（完全信息期望值）

* __完全信息先验期望值 / 先验EVPI__：记$a_{opt} = \arg\min_\limits{a_j \in \cal{A}} E_{\theta \sim\pi(\theta)} L(\theta_i, a_j)$, 则__先验EVPI__ = $E_{\theta \sim \pi(\theta)} L(\theta, a_{opt}) = \min_\limits{a_j \in \cal{A}} E_{\theta \sim\pi(\theta)} L(\theta_i, a_j)$
* __完全信息后验期望值 / 后验EVPI__：记$\delta_{opt} = \arg\min_\limits{\delta_j \in D} E_{\theta \mid x \sim \pi(\theta \mid x)} \left[ L(\theta, \delta_j) \right]$ ，则__后验EVPI__= $E_{\theta \mid x \sim \pi(\theta \mid x)}  L(\theta, \delta_{opt}) = \min_\limits{\delta_j \in D} E_{\theta \mid x \sim \pi(\theta \mid x)} \left[ L(\theta, \delta_j) \right] $

* __后验EVPI期望值__=$E_{x \sim m(x)} \left( E_{\theta \mid x \sim \pi(\theta \mid x)} \left[ L(\theta, \delta_{opt}) \right] \right)$

* __抽样信息期望值 / EVSI__ = __先验EVPI - 后验EVPI期望值__
  $$
  EVSI = E_{\theta \sim \pi(\theta)} L(\theta, a_{opt}) - E_{x \sim m(x)} \left( E_{\theta \mid x \sim \pi(\theta \mid x)} \left[ L(\theta, \delta_{opt}) \right] \right)
  $$

  * $EVSI$代表了抽样给决策者带来的增益
  * $EVSI$随样本量的变化而变化，所以也可记为$EVSI(n)$

## 5.5 最佳样本量的确定

* __抽样净益($ENGS$)__：记$C(n) = C_f + C_v n (n \in \mathbb{Z}^+)$为抽样成本，则__抽样净益__$ENGS = EVSI(n) - C(n)$

* __最佳样本量($n^*$)__:   $n^* = \arg\max_\limits{n \in \mathbb{Z}^+} ENGS(n)$
* __上界__: 由$C(n^*) \leq EVSI(n*) \leq 先验EVPI \Rightarrow n^* \leq \frac{先验EVPI - C_f}{C_v}$



# 第六章 统计决策理论 （抽样信息）

## 6.1 风险函数

* __风险函数__：$R(\theta_i, \delta_j) = E_{x \sim p(x; \theta)}L(\theta_i, \delta_j(x))$
  * 不同的损失函数有不同的风险函数
  * 比较两个函数$R(\theta_i, \delta_1)$和$R(\theta_i, \delta_2)$是困难的，所以风险函数还不能直接用于决策使用
* __决策函数的最优性__
  * __一致优__：$\forall \theta_i \in \Theta, R(\theta_i, \delta_1) \leq R(\theta_i, \delta_2)$, 并且$\exists \theta_0 \in \Theta, R(\theta_i, \delta_1) < R(\theta_i, \delta_2)$，则称$\delta_1$一致优于$\delta_2$
  * __等价__：$\forall \theta_i \in \Theta, R(\theta_i, \delta_1) = R(\theta_i, \delta_2)$
* __一致最小风险决策函数__： $\forall \theta_i \in \Theta, \delta \in \cal D, R(\theta_i, \delta^*) \leq R(\theta_i, \delta)$
  
* 一致最优估计
  
* 例子: 统计决策中的假设检验问题

  > ​	$x = (x_1, \cdots, x_n) \sim p(x \mid \theta)$
  >
  > ​	$\Theta = \{\Theta_0, \Theta_1 \}$
  >
  > ​	$\cal A = \{0(接受)，1(拒绝) \}$
  >
  > ​	原假设$H_0$, 备择假设$H_1$
  >
  > ​	拒绝域$W = \{x:\delta(x)=1 \} \in \cal X$
  >
  > ​	$\delta(x) = \begin{cases} 1, x \in W \\ 0, x \not\in W  \end{cases}$
  >
  > ​	$L(\theta, 0) = \begin{cases} 0, \theta \in \Theta_0 \\ 1, \theta \in \Theta_1  \end{cases} $, $L(\theta, 1) = \begin{cases} 0, \theta \in \Theta_1 \\ 1, \theta \in \Theta_0  \end{cases} $
  >
  > ​	$\begin{align} R(\theta, \delta) &= E_{x\mid \theta \sim p(x\mid \theta)} L(\theta, \delta(x)) \\ &= \int_{\delta(x)=1} L(\theta, \delta(x))p(x \mid \theta) {\rm dx} + \int_{\delta(x)=0} L(\theta, \delta(x))p(x \mid \theta) {\rm dx} \\ &= \int_{W} L(\theta, \delta(x))p(x \mid \theta) {\rm dx} + \int_{\overline{W}} L(\theta, \delta(x))p(x \mid \theta) {\rm dx} \\ &= \begin{cases} P_{x \mid \theta \sim p(x\mid\theta)}(x \in W), \theta \in \Theta_0 --- (Type\ I\ error, \alpha)\\ P_{x \mid \theta \sim p(x\mid\theta)}(x \not\in W), \theta \in \Theta_1 --- (Type\ II\ error, \beta)\end{cases} \end{align}$ 
  >
  > ​	N-P准则：
  >
  > ​		寻找决策函数$\delta^*(x)$,在满足$\sup_\limits{\theta \in \Theta_0}R(0, \delta^*(x)) \leq \alpha$的条件下，使$\forall \theta \in \Theta_1, \delta \in \cal{D}, R(\theta, \delta^*(x)) \leq R(\theta, \delta)$

## 6.2 容许性

* 利用风险函数，在决策函数类中挑选一致最优决策函数常常是难以实现的，所以要用降低要求
* 利用__容许行__替代__一致最优性__

* 定义于行动的容许行类似
* Stein effect：在多元二次损失函数下，当$p \geq 3$时，样本均值向量是正态均值向量的非容许估计

## 6.3 最小最大（风险）准则

* 悲观准则

* $\max_\limits{\theta \in \Theta}R(\theta, \delta_j)$：代表了决策$\delta_j$所能引发的最大风险

* $\delta^* = \arg\min_\limits{\delta \in \cal D} \max_\limits{\theta \in \Theta} R(\theta, \delta) = \arg\min_\limits{\delta \in \cal D} \max_\limits{\theta \in \Theta} E_{x\mid \theta \sim p(x\mid \theta)} L(\theta, \delta)$

### 6.3.2 最小最大估计 与 容许估计 的关系

* 唯一最小最大估计是容许估计
* 容许估计对应的风险函数为常数则也为最小最大估计

## 6.4 贝叶斯风险准则

* 贝叶斯风险: $R(\delta_j) = E_{\theta \sim \pi(\theta)} R(\theta, \delta_j)$
* $\delta^* = \arg\min_\limits{\delta \in \cal D} R(\delta) = \arg\min_\limits{\delta \in \cal D} E_{\theta \sim \pi(\theta)} R(\theta, \delta)$

* 贝叶斯风险 $\iff$ 后验风险

  $\begin{align} R(\delta_j) &= E_{\theta \sim \pi(\theta)} R(\theta, \delta_j) \\ &= \int_{\Theta} \left( \int_{\cal X} L(\theta, \delta)p(x\mid\theta){\rm dx}\right) \pi(\theta) {\rm d\theta} \\ &= \int_{\cal X} \left( \int_{\Theta} L(\theta, \delta)\pi(\theta\mid x){\rm d\theta}\right) m(x) {\rm dx} \\ &= \int_{\cal X} R(\delta\mid x)m(x) {\rm dx} \end{align} $

### 6.4.1 贝叶斯估计 与 容许估计 的关系

* 贝叶斯估计的贝叶斯风险有限，则也为容许估计
* 贝叶斯估计唯一，则为容许估计

### 6.4.2 贝叶斯估计 与 最小最大估计 的关系

* 贝叶斯估计的风险函数为常数，则也为最小最大估计



# Summary

​	所谓做决策实际上就是在决策函数类中选取风险最小的一个，即
$$
\arg \min_\limits{\delta(x) \in \cal D} Risk
$$
所以明确了各类风险的定义及关系就可以明确如何做决策。

而风险的定义是从损失函数$L(\theta_i, \delta_j(x))$出发的。

* $\delta_j$的先验风险：$\overline{L(\delta_j)} = E_{\theta \sim \pi(\theta)} L(\theta, \delta_j)$ ----------------------------- 先验期望风险准则
* $\delta_j$的后验风险：$R(\delta_j \mid x) = E_{\theta\mid x \sim \pi(\theta\mid x)} L(\theta, \delta_j)$ -------------------- ==后验期望风险准则==
  * 当$L(\theta, \delta_j) = \begin{cases} 0 & \theta = \delta_j \\ 1 & otherwise \end{cases}$(0-1)损失函数 ----------------- ==最小错误率准则==
* $\delta_j$的风险函数：$R(\theta_i, \delta_j) = E_{x\mid \theta \sim p(x\mid \theta)} L(\theta_i, \delta_j)$ ------------------- 一致最小风险准则
  * 一致优很难找，对风险函数的一些侧面进行比较
    * $\delta_j$的   最大 风险：$\max_\limits{\theta \in \Theta} R(\theta, \delta_j)$ ------------------------------ 最小最大风险准则
    * $\delta_j$的贝叶斯风险：$R(\delta_j) = E_{\theta \sim \pi(\theta)} R(\theta, \delta_j)$ -------------- ==贝叶斯风险准则==
  * 在假设检验中，固定一类错误，最小化另一类错误
    * $\arg\min_\limits{\delta \in \sup_\limits{\theta \in \Theta_0}R(\theta, \delta) \leq \alpha} R(\theta, \delta), \forall \theta \in \Theta_1$ -------------------------- N-P准则





